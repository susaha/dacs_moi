source ~/panoptic/bin/activate

echo "temp directory for the job" $TMPDIR
TARGET_DIR_CITY=${TMPDIR}/datasets/cityscapes_4_panoptic_deeplab/cityscapes/
mkdir -p TARGET_DIR_CITY
echo  "Data directory for CITYSCAPE PANOPTIC DEEPLAB job is :: " TARGET_DIR_CITY
SOURCE_DIR=/cluster/work/cvl/susaha/dataset/panoptic-datasets/cityscapes-tars/
time python unpack_dataset.py ${TARGET_DIR_CITY} ${SOURCE_DIR} --num_jobs=6
now=$(date +"%T")
echo "time before unpacking : $now"

echo "temp directory for the job" $TMPDIR
TARGET_DIR_SYN_RAND=${TMPDIR}/datasets/Synthia/RAND_CITYSCAPES
mkdir -p TARGET_DIR_SYN_RAND
echo  "Data directory for the SYN RAND job is :: " TARGET_DIR_SYN_RAND
SOURCE_DIR=/cluster/work/cvl/susaha/dataset/panoptic-datasets/rand_cityscape_tars/
time python unpack_dataset.py ${TARGET_DIR_SYN_RAND} ${SOURCE_DIR} --num_jobs=4
now=$(date +"%T")
echo "time before unpacking : $now"

## list videos and check space
TARGET_DIR=${TMPDIR}/datasets/
echo "number of videos extracted are:: "
ls ${TARGET_DIR} | wc -l
echo "Space consumption is:: "
du -hs ${TARGET_DIR}
now=$(date +"%T")
echo "time after checking space : $now"

DEBUG='False'
YML_FNAME='ctrl/yml-config-panop/exp_common.yml'
MS_EXP_ROOT='/cluster/work/cvl/susaha/experiments/CVPR2022/cvpr2022_run_from_my_euler' # use this when running exp on your Euler
#MS_EXP_ROOT='/cluster/work/cvl/susaha/experiments/CVPR2022/cvpr2022_run_from_guru_euler'


STR1=$(date +%m-%Y)
STR11="exproot_"
EXPROOT="$STR11$STR1"
STR2=$(date +%d-%m-%Y)
STR22="phase_"
PHASENAME="$STR22$STR2"
subp=$(date +%T_%6N | sed "s/:/_/g")
STR3=${subp//[_]/-}
STR33="subphase_"
SUB_PHASENAME="$STR33$STR3"


BSUB_SCRIPT_FNAME='euler_script.sh' # TODO

# --------------------------------------------------------------
# ----------DACS related new configs -----------------
# --------------------------------------------------------------
USE_DEPTH=False
SYNTHIA_DATALOADING_MODE='original_only'
CITYSCAPES_DATALOADING_MODE='dacs'
ACTIVATE_PANOPTIC_EVAL=False
DATASET_RANDOM_CROP_DIM=512 #
#--------------------------------------------
TRAIN_TRAIN_WITH_DACS=True
WEIGHT_INITIALIZATION_DACS_COCO_MODEL=True
WEIGHT_INITIALIZATION_DADA_DEEPLABV2=False
MODEL_TYPE='dacs_old'
TRAIN_SCRIPT_NAME='train_panop_dacs'
DACS_RANDOM_CROP=True
ENABLE_DISCRIMINATOR=False
DATALOADER_NUM_WORKERS=4 # TODO: original 2
TRAIN_IMS_PER_BATCH=2 # TODO: original 1
TRAIN_FREEZE_BN=False # TODO
TRAIN_MAX_ITER=250000
ACTIVATE_SEMANITC_EVAL=True
ACTIVATE_PANOPTIC_EVAL=False
# ---------------------------------------------------------------

MODEL_SUB_TYPE='deeplabv2'
MODEL_FILE='dada_model_new'
LOSS_SEMANTIC_NAME='dada_sem_loss'
PRETRAINED_WEIGHTS_FOR_TRAIN='DADA_IMGNET'
PANOPTIC_DEEPLAB_STYLE_LR=False
DADA_STYLE_LR=True

TRAIN_TRAIN_INSTANCE_BRANCH=False
TRAIN_TRAIN_DEPTH_BRANCH=False
ADV_FEATURE_MODE=1
DISC_INP_DIM=16
BASE_LR=0.00025
DISC_LR=0.0001

LOSS_CENTER_WEIGHT=20.0
LOSS_OFFSET_WEIGHT=0.01
LOSS_DEPTH_WEIGHT=0.001
TRAIN_SAVE_PRED_EVERY=30000
TRAIN_TENSORBOARD_VIZRATE=5000
TRAIN_DISPLAY_LOSS_RATE=20
TRAIN_EVAL_EVERY=5000
EXP_SETUP='SYNTHIA_TO_CITYSCAPES'
TRAIN_IMGNET_PRETRAINED_MODEL_PATH='/cluster/work/cvl/susaha/dataset/panoptic-datasets'
GPUS=[0]
TRAIN_ONLY_SOURCE=False
TRAIN_INPUT_SIZE_SOURCE=[1280,760]
TRAIN_INPUT_SIZE_TARGET=[1024,512]
TEST_INPUT_SIZE_TARGET=[1024,512]
TEST_OUTPUT_SIZE_TARGET=[2048,1024]


# TRAINING
#python -m torch.distributed.launch --nproc_per_node=4 main_panop.py \
CUDA_VISIBLE_DEVICES=0 python main.py \
--debug $DEBUG \
--yml_fname $YML_FNAME \
GPUS $GPUS \
DATA_ROOT ${TARGET_DIR} \
MS_EXP_ROOT $MS_EXP_ROOT \
EXP_ROOT $EXPROOT \
PHASE_NAME $PHASENAME \
SUB_PHASE_NAME $SUB_PHASENAME \
TRAIN.TRAIN_INSTANCE_BRANCH $TRAIN_TRAIN_INSTANCE_BRANCH \
TRAIN.TRAIN_DEPTH_BRANCH $TRAIN_TRAIN_DEPTH_BRANCH \
ADV_FEATURE_MODE $ADV_FEATURE_MODE \
DISC_INP_DIM $DISC_INP_DIM \
SOLVER.BASE_LR $BASE_LR \
SOLVER.DISC_LR $DISC_LR \
LOSS.SEMANTIC.NAME $LOSS_SEMANTIC_NAME \
TRAIN.FREEZE_BN $TRAIN_FREEZE_BN \
LOSS.CENTER.WEIGHT $LOSS_CENTER_WEIGHT \
LOSS.OFFSET.WEIGHT $LOSS_OFFSET_WEIGHT \
LOSS.DEPTH.WEIGHT $LOSS_DEPTH_WEIGHT \
TRAIN.MAX_ITER $TRAIN_MAX_ITER \
DATALOADER.NUM_WORKERS $DATALOADER_NUM_WORKERS \
TRAIN.IMS_PER_BATCH $TRAIN_IMS_PER_BATCH \
TRAIN.SAVE_PRED_EVERY $TRAIN_SAVE_PRED_EVERY \
TRAIN.TENSORBOARD_VIZRATE $TRAIN_TENSORBOARD_VIZRATE \
TRAIN.DISPLAY_LOSS_RATE $TRAIN_DISPLAY_LOSS_RATE \
TRAIN.EVAL_EVERY $TRAIN_EVAL_EVERY \
EXP_SETUP $EXP_SETUP \
TRAIN.IMGNET_PRETRAINED_MODEL_PATH $TRAIN_IMGNET_PRETRAINED_MODEL_PATH \
MODEL_TYPE $MODEL_TYPE \
MODEL_SUB_TYPE $MODEL_SUB_TYPE \
TRAIN_ONLY_SOURCE $TRAIN_ONLY_SOURCE \
ENABLE_DISCRIMINATOR $ENABLE_DISCRIMINATOR \
TRAIN.INPUT_SIZE_SOURCE $TRAIN_INPUT_SIZE_SOURCE \
TRAIN.INPUT_SIZE_TARGET $TRAIN_INPUT_SIZE_TARGET \
TEST.INPUT_SIZE_TARGET $TEST_INPUT_SIZE_TARGET \
TEST.OUTPUT_SIZE_TARGET $TEST_OUTPUT_SIZE_TARGET \
PRETRAINED_WEIGHTS_FOR_TRAIN $PRETRAINED_WEIGHTS_FOR_TRAIN \
PANOPTIC_DEEPLAB_STYLE_LR $PANOPTIC_DEEPLAB_STYLE_LR \
DADA_STYLE_LR $DADA_STYLE_LR \
BSUB_SCRIPT_FNAME $BSUB_SCRIPT_FNAME \
MODEL_FILE $MODEL_FILE \
TRAIN.TRAIN_WITH_DACS $TRAIN_TRAIN_WITH_DACS \
WEIGHT_INITIALIZATION.DACS_COCO_MODEL $WEIGHT_INITIALIZATION_DACS_COCO_MODEL \
WEIGHT_INITIALIZATION.DADA_DEEPLABV2 $WEIGHT_INITIALIZATION_DADA_DEEPLABV2 \
TRAIN_SCRIPT_NAME $TRAIN_SCRIPT_NAME \
DACS_RANDOM_CROP $DACS_RANDOM_CROP \
DATASET.RANDOM_CROP_DIM $DATASET_RANDOM_CROP_DIM \
ACTIVATE_PANOPTIC_EVAL $ACTIVATE_PANOPTIC_EVAL \
ACTIVATE_SEMANITC_EVAL $ACTIVATE_SEMANITC_EVAL \
USE_DEPTH $USE_DEPTH \
SYNTHIA_DATALOADING_MODE $SYNTHIA_DATALOADING_MODE \
CITYSCAPES_DATALOADING_MODE $CITYSCAPES_DATALOADING_MODE \
ACTIVATE_PANOPTIC_EVAL $ACTIVATE_PANOPTIC_EVAL
# EVALUATION
#CUDA_VISIBLE_DEVICES=0 python main_eval_panop_old.py \
