from yacs.config import CfgNode as CN
from ctrl.config_panop.add_remaining_cfg_params import add_remaining_params
import torch


_C = CN()


_C.IGNORE_TOP_BOTTOM_AT_VISUAL = False
_C.FDIST_SCALE_MIN_RATIO = 0.75
_C.FDIST_LAMBDA = 0.005 # 0.0005, 0.0001, 0.0.000075

_C.UNLABELED_CENTER_LOSS_WEIGHT=10.0
_C.UNLABELED_OFFSET_LOSS_WEIGHT=0.01
# Ignoring the top and bottom of the pseduo label weight following DAFormer (L. Hoyer)
_C.PSEUDO_WEIGHT_IGNORE_TOP=False # set it to true when target is cityscapes, for mapillary let it be false
_C.PSEUDO_WEIGHT_IGNORE_TOP_VAL=15 # TODO: GET IT FROM DAFORMER
_C.PSEUDO_WEIGHT_IGNORE_BOTTOM=False # set it to true when target is cityscapes, for mapillary let it be false
_C.PSEUDO_WEIGHT_IGNORE_BOTTOM_VAL=120 # TODO: GET IT FROM DAFORMER
_C.DEACTIVATE_UNLABELED_CENTER_OFFSET_LOSS=False
_C.APPLY_CENTER_LOSSES_THRESHOLDING=False
_C.CENTER_LOSSES_THRESHOLD=0.0
_C.SET_DETECT_ANOMALY = False # as per pytroch we should not use this for actual training, it slows down the training, setting it false, onlz use this for debug purpose

_C.ACTIVATE_DAFORMER_FEAT_DIST_LOSS=False
_C.INIT_MODEL_WITH_DACS_IMGNET_COCO_WEIGHTS=True
_C.INIT_MODEL_WITH_IMGNET_WEIGHTS=False
_C.INIT_MODEL_WITH_DADA_IMGNET_WEIGHTS=False
_C.RESENT101_IMGNET_WEIGHTS_URL='https://download.pytorch.org/models/resnet101-5d3b4d8f.pth'
_C.DADA_RESENT101_IMGNET_WEIGHTS_URL='/home/suman/Downloads/DeepLab_resnet_pretrained_imagenet.pth'
_C.RESUME_TRAINING_FROM_CHECKPOINT=False

_C.ARMASUISSE_FILE_START=0
_C.ARMASUISSE_FILE_END=11151
_C.TRAIN_EMA_MODEL=True
_C.UDA_SETUP='S2C'
_C.MODEL_TYPE='DEEPLABV2'
_C.SAVE_VISUALS_AFTER=10000

_C.RESUME_TRAINING_OF_UNLABELED_INSTANCE_LOSS_MODELS_FROM_PREVIOUS_CHECKPOINT=False
_C.PREVIOUS_CHECKPOINT_PATH=''
_C.PANOPTIC_DEEPLAB_DEPTH_FUSION_TYPE=''
_C.APPLY_RARE_CLASS_SAMPLING=False
_C.EXCLUDE_MODELS=''
_C.MODEL_PATH=''
_C.MODEL_PATH2=''
_C.APPLY_PANOPTIC_DEEPLAB_AUGMENTATION=False
_C.PANOPTIC_DEEPLAB_TRANSFORMS_RANDOM_SCALES=[0.5,2.0,0.1]
_C.TRAIN_S2M_WITH_S2C_PRETRAINED = False
_C.MAPILLARY_DATA_LOADING_STYLE = 'DADA' # DADA or OURS
_C.NUM_VAL_SAMPLES_DURING_DEBUG = 10
_C.SYNTHIA_CROWD_THRESHOLD = 0

# inputs for main_panop_das_moi_corda
_C.TASKNAMES = [0,1,2] # ["S", "D", "I"]
# _C.NUM_OUTPUT = {"S": 16, "D": 1, "I": 128, "D_src": 1}

_C.LOAD_CITYSCAPES_CORDA_DEPTH_LABELS=False
_C.APPLY_CLIP_GRAD_NORM=False
_C.MAX_NORM_VALUE = 0.0
_C.INST_DEPTH_FUSION_MODE=0
_C.SELECT_ONLY_THINGS_IN_CLASSMIX=False
_C.ACTIVATE_VISUALS_FOR_MOIV2=False
# main_panop_dacs_v2_moi
_C.PANOP_DACS_V2_TRAIN_FROM_SCRATCH=False
_C.PANOP_DACS_V2_TARGET_CENTER_LOSS_WEIGHT = 20.0
_C.PANOP_DACS_V2_TARGET_OFFSET_LOSS_WEIGHT = 0.01
_C.PANOP_DACS_V2_FREEZE_BACKBONE = False
_C.PANOP_DACS_V2_FREEZE_DADA_AUXBLOCK = False
_C.PANOP_DACS_V2_FREEZE_SEMANTIC_HEAD = False
_C.PANOP_DACS_V2_EVAL_CKPT_PATH=''

# pseudo label generation for center and offset
_C.THRESHOLD_CENTER = 0.9
_C.CENTER_PSEUDO_LBL_MIN_PXL = 100 # minimum valid pixels for generating center pseduo labels, valid means, if the pixel belong to a instance class then only it is a valid center predction
_C.GEN_OFFSET_PSEUDO_LABELS = False
_C.GEN_PSEDUO_LABEL_WRONG_VERSION=False
_C.GROUP_PXL_WITH_FORLOOP=False

# PLCA (pixel level cycle association loss)
# --- PLCA: START ---
_C.PLCA = CN()
_C.PLCA.SPAGG_ALPHA = 0.5
_C.PLCA.ASSO_W = 0.1
_C.PLCA.GET_EMA_MODEL_TARGET_PRED=True
_C.PLCA.USE_DACS_PSEUDO_LABELS_FOR_ASSO=False
_C.PLCA.USE_DACS_PSEUDO_LABELS_FOR_ASSO_AFTER=0

# --- PLCA: END ---

# --- DACS: START ---
_C.DACS = CN()
_C.DACS.num_classes = 19
_C.DACS.model = "DeepLab"
_C.DACS.dataset = "cityscapes"
_C.DACS.dataset_2nd = "synthia"
_C.DACS.seed = 1
_C.DACS.pretrained = "coco"
_C.DACS.ignore_label = 255
_C.DACS.save_unlabeled_images = True
_C.DACS.gpus = 0
_C.DACS.training = CN()
_C.DACS.training.batch_size = 2
_C.DACS.training.num_workers = 4
_C.DACS.training.optimizer = "SGD"
_C.DACS.training.momentum = 0.9
_C.DACS.training.num_iterations = 250000
_C.DACS.training.learning_rate = 2.5e-4
_C.DACS.training.lr_schedule = "Poly"
_C.DACS.training.lr_schedule_power = 0.9
_C.DACS.training.weight_decay = 5e-4
_C.DACS.training.use_sync_batchnorm = True
_C.DACS.training.data = CN()
_C.DACS.training.data.split_id_list = 0
_C.DACS.training.data.labeled_samples = 0
_C.DACS.training.data.input_size = (512,512)
_C.DACS.training.data.scale = False
_C.DACS.training.data.crop = True
_C.DACS.training.unlabeled = CN()
_C.DACS.training.unlabeled.train_unlabeled = True
_C.DACS.training.unlabeled.consistency_weight = 1
_C.DACS.training.unlabeled.consistency_loss = "CE"
_C.DACS.training.unlabeled.pixel_weight = "threshold_uniform"
_C.DACS.training.unlabeled.mix_mask = "class"
_C.DACS.training.unlabeled.flip = False
_C.DACS.training.unlabeled.color_jitter = True
_C.DACS.training.unlabeled.blur = True
_C.DACS.utils = CN()
_C.DACS.utils.save_checkpoint_every = 5000
_C.DACS.utils.checkpoint_dir = ""
_C.DACS.utils.val_per_iter = 5000
_C.DACS.utils.tensorboard = True
_C.DACS.utils.log_per_iter = 20
_C.DACS.utils.tesnorboard_log_per_iter = 100
_C.DACS.utils.save_best_model = True
_C.DACS.utils.show_best_model_info_every_after = 100
_C.DACS.utils.show_gpu_mem_usage_every_after = 500
# --- DACS: END ---
# -----------
_C.NOT_IN_USE = True
_C.USE_TRAIN_PANOP_ORIGINAL = True # not in use
_C.TRAIN_SCRIPT_NAME = 'train_panop_original' #  train_panop or train_panop_dacs
_C.DEBUG = False
_C.MACHINE = 0
_C.BSUB_SCRIPT_FNAME=''
_C.GPUS = (0,)
_C.MODEL_TYPE = 'panop_v1'
_C.MODEL_SUB_TYPE = 'deeplabv3'
_C.MODEL_FILE = ''
_C.USE_DATA_PARALLEL = False
_C.ENABLE_DISCRIMINATOR = False
_C.TRAIN_DISC_EVERY = 1
_C.ENABLE_DISCRIMINATOR_2ND = False
_C.DUMP_PANOPTIC_VISUAL_IMGS = False
_C.DISCRIMINATOR_TYPE = 'dada'
_C.DISCRIMINATOR_TYPE_2ND = 'dada'
_C.TRANSFORMER_ENCODER_D_MODEL = 512
_C.TRANSFORMER_ENCODER_NUM_HEAD = 8
_C.TRAIN_ONLY_SOURCE = True
_C.TRAIN_ORACLE = False
_C.DADA_STYLE_LR = False
_C.DADA_STYLE_DEPTH_HEAD = False
_C.PANOPTIC_DEEPLAB_STYLE_LR = True
_C.REPRODUCE_PANOPTIC_DEEPLAB = False
_C.PANOPTIC_DEEPLAB_DATA_AUG_ALL = False
_C.PANOPTIC_DEEPLAB_DATA_AUG_ONLY_NORM = False
_C.PANOPTIC_DEEPLAB_DATA_AUG_RANDOM_CROP = False
_C.PRETRAINED_WEIGHTS_FOR_TRAIN = 'DADA_IMGNET' # IMGNET or DADA_IMGNET # TODO
_C.ACTIVATE_PANOPTIC_EVAL = False
_C.ACTIVATE_SEMANITC_EVAL = True
_C.ACTIVATE_ONLY_PANOPTIC_EVAL = False
_C.DACS_RANDOM_CROP = False
_C.ACTIVATE_DACS_UNLABELED_LOSS = False
_C.INCLUDE_DADA_AUXBLOCK = False
_C.INCLUDE_DEPTH_FUSION = False
#---------------------------------------------
# these params are added to train either
# Danda's or Rui's approach
#--------------------------------- ------------
_C.APPROACH_TYPE = 'OTHERS' # or 'DANDA'
_C.APPROACH_DANDA_CONCAT_PE = False # concat world coordinate with features
# Danda's approach
_C.ROI_ALIGN_WINDOW_SIZE = 112 # (7 * 16)
_C.ACTIVATE_DANDA_MEMORY_MODULE = False
_C.DANDA_MEMORY_MODULE_NUM_FEATURES = 200
_C.DANDA_MEMORY_MODULE_FEAT_DIM = 20

# Rui's MHA approach
_C.MHA = CN()
_C.MHA.ACTIVATE_MHA = False
_C.MHA.LOCATION = 'BACKBONE_RES5' # BACKBONE_RES3, 'DECODER_FEAT', 'HEAD_FEAT'
_C.MHA.TYPE = 'BACKBONE_FEAT' # 'CROSS_TASK_SEM_DEP', 'CROSS_TASK_SEM_INS', 'WITHIN_DOMAIN', 'CROSS_DOMAIN'
_C.MHA.FUSION_TYPE1 = 'add'
_C.MHA.INP_DIM1 = 2048
_C.MHA.OUT_DIM = 512
_C.MHA.INP_DIM2 = 256
_C.MHA.INP_DIM3 = 128
_C.MHA.OUT_DIM2 = 128
_C.MHA.WITH_PE = False
# _C.ACTIVATE_MHA_BLOCK = False # _C.MHA.ACTIVATE_MHA
# _C.MHA_ON_RES5_FEAT = True # _C.MHA.LOCATION
# _C.MHA_ON_CROSS_TASK = True # _C.MHA.TYPE
# _C.MHA_FUSION_TYPE = 'add' # _C.MHA.FUSION_TYPE
#---------------------------------------------

_C.MHA_DADA = CN()
_C.MHA_DADA.ACTIVATE_MHA = False # TODO: False,True
_C.MHA_DADA.EMBED_DIM = 128
_C.MHA_DADA.NUM_HEADS = 8
_C.MHA_DADA.MODE = 0 # TODO: 0,1,2
_C.MHA_DADA.POS_ENCODING = True # TODO: True, False
_C.MHA_DADA.AVG_POOL_DIM_SRC = (0, 0) # TODO:
_C.MHA_DADA.AVG_POOL_DIM_TAR = (0, 0) # TODO:
_C.MHA_DADA.UPSAMPLE_SHAPE_SRC = (0, 0) # TODO:
_C.MHA_DADA.UPSAMPLE_SHAPE_TAR = (0, 0) # TODO:
_C.MHA_DADA.SUM_DIM = 2


_C.USE_DEPTH = True
# _C.USE_INSTANCE_FOR_ADV_LOSS = False
_C.ADV_FEATURE_MODE = 1
_C.DISC_INP_DIM = 16 # (_C.NUM_CLASSES * 2) + _C.NUM_DEPTH_BINS  # 16+16+15 = 47 ; or 7+7+15 = 29
_C.DISC_INP_DIM_2ND = 0
_C.DISC_INP_DIMS = CN()
_C.DISC_INP_DIMS.K4 = [0,0]
_C.DISC_INP_DIMS.K5 = [0,0]
_C.DISC_INP_DIMS.K6 = [0,0]
_C.DISC_INP_DIMS.K7 = [0,0]
_C.DISC_INP_DIMS.K8 = [0,0]
_C.DISC_INP_DIMS.K9 = [0,0]
_C.DISC_INP_DIMS.K10 = [0,0]
_C.DISC_INP_DIMS.K11 = [0,0]
_C.DISC_INP_DIMS.K12 = [0,0]
_C.DISC_INP_DIMS.K13 = [0,0]
_C.DISC_INP_DIMS.K14 = [0,0]
_C.EXP_SETUP = 'SYNTHIA_TO_CITYSCAPES'
_C.DADA_MODEL_BACKBONE = 'ctrl'

_C.NUM_CLASSES = 16
_C.SOURCE = 'SYNTHIA'
_C.TARGET = 'Cityscapes'
_C.RESO = 'FULL'
_C.SYNTHIA_DATALOADING_MODE = 'panoptic'
_C.CITYSCAPES_DATALOADING_MODE = 'panoptic'
_C.DATA_LIST_SOURCE = 'ctrl/dataset/synthia_list/{}.txt'
_C.DATA_LIST_TARGET = 'ctrl/dataset/cityscapes_list/{}.txt'

# experiment related paths, e.g., exp_root, data_root etc.
# the values are passed in the commandline
_C.DATA_ROOT = ''
_C.MS_EXP_ROOT = ''
_C.EXP_ROOT = ''
_C.PHASE_NAME = ''
_C.SUB_PHASE_NAME = ''
_C.PRET_MODEL = ''


# panoptic-deeplab data augmentation related params
_C.DATASET = CN()
_C.DATASET.CROP_SIZE = (1281, 761)
_C.DATASET.RANDOM_CROP_DIM = 512  # this is not used for panoptic deeplab random crop, this is i introduced for dada
_C.DATASET.MIRROR = True
_C.DATASET.MIN_SCALE = 0.5
_C.DATASET.MAX_SCALE = 2.0
_C.DATASET.SCALE_STEP_SIZE = 0.1
_C.DATASET.MEAN = (0.485, 0.456, 0.406)
_C.DATASET.STD = (0.229, 0.224, 0.225)

_C.DATALOADER = CN()
_C.DATALOADER.SAMPLER_TRAIN_SOURCE = 'TrainingSamplerSource'
_C.DATALOADER.SAMPLER_TRAIN_TARGET = 'TrainingSamplerTarget'
_C.DATALOADER.SAMPLER_TEST_TARGET = 'TestingSamplerTarget'
_C.DATALOADER.TRAIN_SHUFFLE = True
_C.DATALOADER.NUM_WORKERS = 0

_C.PANOPTIC_TARGET_GENERATOR = CN()
_C.PANOPTIC_TARGET_GENERATOR.IGNORE_LABEL = 255
_C.PANOPTIC_TARGET_GENERATOR.LABEL_DIVISOR = 1000
_C.PANOPTIC_TARGET_GENERATOR.IGNORE_STUFF_IN_OFFSET = True
_C.PANOPTIC_TARGET_GENERATOR.SMALL_INSTANCE_AREA = 4096
_C.PANOPTIC_TARGET_GENERATOR.SMALL_INSTANCE_WEIGHT = 3
_C.PANOPTIC_TARGET_GENERATOR.SIGMA = 8
_C.PANOPTIC_TARGET_GENERATOR.TARGET_KEYS = ('semantic', 'center', 'offset', 'semantic_weights', 'center_weights', 'offset_weights')
_C.PANOPTIC_TARGET_GENERATOR.OUTPUT_KEYS = ('semantic', 'center', 'offset')


# MODEL
_C.MODEL = CN()
_C.MODEL.WEIGHTS = ''
_C.MODEL.BN_MOMENTUM = 0.01

_C.MODEL.BACKBONE = CN()
_C.MODEL.BACKBONE.DILATION = (False, False, False)
_C.MODEL.BACKBONE.WEIGHTS = ''
_C.MODEL.BACKBONE.PRETRAINED = True

_C.MODEL.DECODER = CN()
_C.MODEL.DECODER.IN_CHANNELS = 2048
_C.MODEL.DECODER.FEATURE_KEY = 'res5'
_C.MODEL.DECODER.DECODER_CHANNELS = 256
_C.MODEL.DECODER.ATROUS_RATES = (3, 6, 9)

_C.MODEL.PANOPTIC_DEEPLAB = CN()
_C.MODEL.PANOPTIC_DEEPLAB.LOW_LEVEL_CHANNELS = (1024, 512, 256)
_C.MODEL.PANOPTIC_DEEPLAB.LOW_LEVEL_KEY = ('res4', 'res3', 'res2')
_C.MODEL.PANOPTIC_DEEPLAB.LOW_LEVEL_CHANNELS_PROJECT = (128, 64, 32)

_C.MODEL.PANOPTIC_DEEPLAB.INSTANCE = CN()
_C.MODEL.PANOPTIC_DEEPLAB.INSTANCE.ENABLE = True
_C.MODEL.PANOPTIC_DEEPLAB.INSTANCE.LOW_LEVEL_CHANNELS_PROJECT = (64, 32, 16)
_C.MODEL.PANOPTIC_DEEPLAB.INSTANCE.DECODER_CHANNELS = 128
_C.MODEL.PANOPTIC_DEEPLAB.INSTANCE.HEAD_CHANNELS = 32
_C.MODEL.PANOPTIC_DEEPLAB.INSTANCE.ASPP_CHANNELS = 256
_C.MODEL.PANOPTIC_DEEPLAB.INSTANCE.NUM_CLASSES = (1, 2)
_C.MODEL.PANOPTIC_DEEPLAB.INSTANCE.CLASS_KEY = ('center', 'offset')

_C.MODEL.PANOPTIC_DEEPLAB.DEPTH = CN()
_C.MODEL.PANOPTIC_DEEPLAB.DEPTH.LOW_LEVEL_CHANNELS_PROJECT = (64, 32, 16)
_C.MODEL.PANOPTIC_DEEPLAB.DEPTH.DECODER_CHANNELS = 128
_C.MODEL.PANOPTIC_DEEPLAB.DEPTH.ASPP_CHANNELS = 256
_C.MODEL.PANOPTIC_DEEPLAB.DEPTH.DECODER_CHANNELS = 128
_C.MODEL.PANOPTIC_DEEPLAB.DEPTH.HEAD_CHANNELS = 32
_C.MODEL.PANOPTIC_DEEPLAB.DEPTH.NUM_CLASSES = (1,)
_C.MODEL.PANOPTIC_DEEPLAB.DEPTH.CLASS_KEY = ('depth',)

_C.WEIGHT_INITIALIZATION = CN()
_C.WEIGHT_INITIALIZATION.DADA_DEEPLABV2 = True
_C.WEIGHT_INITIALIZATION.DADA_PRETRAINED = False
_C.WEIGHT_INITIALIZATION.DADA_PRETRAINED_DEPTH_ENC = False
_C.WEIGHT_INITIALIZATION.DADA_PRETRAINED_SINGLE_CONV_DEC = False
_C.WEIGHT_INITIALIZATION.DADA_PRETRAINED_SEMANTIC_HEAD = False
_C.WEIGHT_INITIALIZATION.RESUME_FROM_SNAPSHOT = False
_C.WEIGHT_INITIALIZATION.RESUME_FROM_SNAPSHOT_GIVEN = False
_C.WEIGHT_INITIALIZATION.DACS_COCO_MODEL = False
_C.WEIGHT_INITIALIZATION.CORDA_PRETRAINED_MODEL_S2C = False

_C.FREEZE_BLOCKS = CN()
_C.FREEZE_BLOCKS.DEPTH_ENC = False

# LOSS
_C.LOSS = CN()

_C.LOSS.SEMANTIC = CN()
_C.LOSS.SEMANTIC.NAME = 'hard_pixel_mining'
_C.LOSS.SEMANTIC.IGNORE = 255
_C.LOSS.SEMANTIC.REDUCTION = 'mean'
_C.LOSS.SEMANTIC.THRESHOLD = 0.7
_C.LOSS.SEMANTIC.MIN_KEPT = 100000
_C.LOSS.SEMANTIC.TOP_K_PERCENT = 0.2
_C.LOSS.SEMANTIC.WEIGHT = 1.0

_C.LOSS.CENTER = CN()
_C.LOSS.CENTER.NAME = 'mse'
_C.LOSS.CENTER.REDUCTION = 'none'
_C.LOSS.CENTER.WEIGHT = 200.0

_C.LOSS.OFFSET = CN()
_C.LOSS.OFFSET.NAME = 'l1'
_C.LOSS.OFFSET.REDUCTION = 'none'
_C.LOSS.OFFSET.WEIGHT = 0.01

_C.LOSS.DEPTH = CN()
_C.LOSS.DEPTH.NAME = 'BerHu'
_C.LOSS.DEPTH.WEIGHT = 0.001
_C.LOSS.DEPTH.WEIGHT_CORDA_UNLABELED = 0.001

_C.LOSS.DISC = CN()
_C.LOSS.DISC.NAME = 'BCE'

_C.LOSS.DACS = CN()
_C.LOSS.DACS.UNLABELED_LOSS = CN()
_C.LOSS.DACS.UNLABELED_LOSS.SEMANTIC = CN()
_C.LOSS.DACS.UNLABELED_LOSS.SEMANTIC.NAME = 'ce2d_pixelwise_weighted'
_C.LOSS.DACS.UNLABELED_LOSS.PIXEL_WEIGHT = 'threshold_uniform'
_C.LOSS.DACS.UNLABELED_LOSS.CONSISTENCY_LOSS = "CE"
_C.LOSS.DACS.UNLABELED_LOSS.CONSISTENCY_WEIGHT = 1

_C.LOSS.HUNGARIAN_BASED_TRIPLET_LOSS = CN()
_C.LOSS.HUNGARIAN_BASED_TRIPLET_LOSS.NAME = 'hungarian_based_triplet_loss'


# SOLVER
_C.SOLVER = CN()
_C.SOLVER.BASE_LR = 0.00025
_C.SOLVER.DISC_LR = 0.0001
_C.SOLVER.DISC_LR_2ND = 0.0001
_C.SOLVER.WEIGHT_DECAY = 0.0
_C.SOLVER.WEIGHT_DECAY_NORM = 0.0
_C.SOLVER.BIAS_LR_FACTOR = 1.0
_C.SOLVER.WEIGHT_DECAY_BIAS = 0.0
_C.SOLVER.OPTIMIZER = "adam"
_C.SOLVER.LR_SCHEDULER_NAME = "WarmupPolyLR"
_C.SOLVER.WARMUP_ITERS = 0
_C.SOLVER.MOMENTUM = 0.9
_C.SOLVER.ADAM_BETAS = (0.9, 0.999)
_C.SOLVER.ADAM_BETAS_DISC_1ST = (0.9, 0.999)
_C.SOLVER.ADAM_BETAS_DISC_2ND = (0.9, 0.999)
_C.SOLVER.ADAM_EPS = 1.0e-8
_C.SOLVER.STEPS = (30000,)
_C.SOLVER.GAMMA = 0.1
_C.SOLVER.WARMUP_METHOD = "linear"
_C.SOLVER.POLY_LR_POWER = 0.9
_C.SOLVER.POLY_LR_CONSTANT_ENDING = 0

_C.SOLVER.CLIP_GRADIENTS = CN()
_C.SOLVER.CLIP_GRADIENTS.ENABLED = False
_C.SOLVER.CLIP_GRADIENTS.CLIP_TYPE = "value"
_C.SOLVER.CLIP_GRADIENTS.CLIP_VALUE = 1.0
_C.SOLVER.CLIP_GRADIENTS.NORM_TYPE = 2.0

_C.SOLVER.WARMUP_FACTOR = 1.0 / 1000


# TRAIN
_C.TRAIN = CN()
_C.TRAIN.IMS_PER_BATCH = 1
_C.TRAIN.RESUME = False
_C.TRAIN.RANDOM_SEED = 1
_C.TRAIN.SET_SOURCE = "all"
_C.TRAIN.SET_TARGET = "train"
_C.TRAIN.DA_METHOD = 'SEMSEG'
_C.TRAIN.MODEL = 'DeepLabv2'
_C.TRAIN.MULTI_LEVEL = False
_C.TRAIN.MAX_ITER = 20
_C.TRAIN.EARLY_STOP = 55000
_C.TRAIN.POWER = 0.9
_C.TRAIN.LAMBDA_SEG = 1.0
_C.TRAIN.LAMBDA_SRH = 1.0
_C.TRAIN.LAMBDA_DEPTH = 0.001
_C.TRAIN.LAMBDA_ADV_MAIN = 0.001
_C.TRAIN.LAMBDA_ADV_MAIN_2ND = 0.001
_C.TRAIN.LAMBDA_HUNGARIAN_BASED_LOSS = 1.0
_C.TRAIN_PANOP_TEMP = False
_C.TRAIN.WEIGHT_DECAY = 0.0005
_C.TRAIN.LEARNING_RATE = 0.00005
_C.TRAIN.LEARNING_RATE_D = 0.0001
_C.TRAIN.MOMENTUM = 0.9
_C.TRAIN.SAVE_PRED_EVERY = 10
_C.TRAIN.TENSORBOARD_VIZRATE = 10
_C.TRAIN.DISPLAY_LOSS_RATE = 1
_C.TRAIN.SNAPSHOT_DIR = ''
_C.TRAIN.INPUT_SIZE_SOURCE = (640, 320)
_C.TRAIN.INPUT_SIZE_TARGET = (640, 320)
_C.TRAIN.RESTORE_FROM = ''
_C.TRAIN.FREEZE_BN = False
_C.TRAIN.EVAL_EVERY = 5000
_C.TRAIN.EVAL_EVERY_PANOP = 30000
_C.TRAIN.TRAIN_INSTANCE_BRANCH = False
_C.TRAIN.TRAIN_DEPTH_BRANCH = True
_C.TRAIN.TRAIN_OFFSET_HEAD = False
_C.TRAIN.CENTER_HEAD_DADA_STYLE = False
_C.TRAIN.IMGNET_PRETRAINED_MODEL_PATH = '/home/suman/apps/code/CVPR2021/MTI_Simon_ECCV2020/mti_simon/dada/pretrained_models'
_C.TRAIN.DADA_PRETRAINED_MODEL_FILE_PATH = ''
_C.TRAIN.TRAIN_DEPTH_INST_TOGETHER = False
_C.TRAIN.DEPTH_INST_FEAT_FUSION_TYPE_WHEHN_NO_MHA = ''
_C.TRAIN.TRAIN_WITH_DACS = False
_C.TRAIN.DACS_IMAGENET_COCO_PRETRAINED_MODEL='http://vllab1.ucmerced.edu/~whung/adv-semi-seg/resnet101COCO-41f33a49.pth'
_C.TRAIN.DACS_UNLABELED_FLIP=False
_C.TRAIN.DACS_COLOR_JITTER=True
_C.TRAIN.DACS_BLUR=True
_C.TRAIN.DACS_SAVE_IMG_EVERY=1000
_C.TRAIN.CORDA_PRETRAINED_MODEL_S2C='/media/suman/CVLHDD/apps/datasets/CORDA/checkpoint/synthia/best_model.pth'
_C.TRAIN.GEN_PANOPTIC_LABELS = True



# TEST
_C.TEST = CN()
_C.TEST.IMS_PER_BATCH = 1
_C.TEST.GPUS = (0,)
_C.TEST.SET_TARGET = "val"
_C.TEST.MODE = 'best'
_C.TEST.BATCH_SIZE_TARGET = 1
_C.TEST.EVAL_INSTANCE = True
_C.TEST.EVAL_PANOPTIC = True
_C.TEST.TEST_TIME_AUGMENTATION = False
_C.TEST.ORACLE_SEMANTIC = False
_C.TEST.DEBUG = False
_C.TEST.INSTANCE_SCORE_TYPE = 'semantic'
_C.TEST.DISPLAY_LOG_EVERY = 50
_C.TEST.INPUT_SIZE_TARGET = (640, 320)
_C.TEST.OUTPUT_SIZE_TARGET = (2048, 1024)
_C.TEST.NUM_TEST_SAMPLES = 1 # from ctrl
_C.TEST.NUM_SAMPLES_DEBUGMODE = 10
_C.TEST.DISP_LOG_EVERY = 100
_C.TEST.CROP_SIZE = (1025, 2049)
_C.ACTIVATE_PERF_COUNTER = False

_C.POST_PROCESSING = CN()
_C.POST_PROCESSING.STUFF_AREA = 2048
_C.POST_PROCESSING.CENTER_THRESHOLD = 0.1
_C.POST_PROCESSING.NMS_KERNEL = 7
_C.POST_PROCESSING.TOP_K_INSTANCE = 200

# --------------------
# CTRL related params
# --------------------
_C.GEN_BINS_IN_CM = False
_C.NUM_DEPTH_BINS = 15
_C.DEPTH_PROCESSING = 'DADA'
_C.DEPTH_SAMPLE_TYPE = 'SID'
# _C.NUM_WORKERS = 2
# _C.NUM_WORKERS_TEST = 2
_C.IS_MIV3_NEW_ARCH =False
_C.CONVERT_PROB_TO_ENTROPY = True
_C.TRAIN_ISL_FROM_SCRATCH = False
_C.NUM_TRAIN_SAMPLES_IN_SOURCE_TARGET = 20
_C.IS_ISL_TRAINING = False
_C.IS_ISL = False

_C.TRAIN.IMG_MEAN = (104.00698793, 116.66876762, 122.67891434)
_C.TEST.IMG_MEAN = (104.00698793, 116.66876762, 122.67891434)
# can't use np.array see the error log below:
# AssertionError: Invalid type <class 'numpy.ndarray'> for key IMG_MEAN; valid types = {<class 'int'>, <class 'bool'>, <class 'str'>, <class 'list'>, <class 'NoneType'>, <class 'float'>, <class 'tuple'>}



def update_config(cfg, args):
    '''
    cfg is the CfgNode _C
    args.yml_fname is the yml file
    args.opts is the list of commandline inputs (key:value pairs)
    '''
    cfg.defrost()

    # overrides _C with yml inputs
    cfg.merge_from_file(args.yml_fname)

    # overrides _C with commandline
    cfg.merge_from_list(args.opts)

    # add few more params to _C
    cfg = add_remaining_params(cfg)

    # if single or multi-gpu training
    cfg.DISTRIBUTED = len(list(cfg.GPUS)) > 1

    cfg.freeze() # TODO: uncomment

