import torch
from ctrl.pxl_cyc_asso.loss import AssociationLoss
from time import perf_counter

'''
do a forward pass of the target image using model
and then take that prediction x2 or probs_T
for target, pass the pseudo label generated by the ema_model
in this way you are asking the model to learn both dacs and pxl_cy_asso based features

x1, x2, gt1, gt2 = probs_S, probs_T, new_gt_S, new_gt_T 
x1, x2 = tensor: 1, 16, 51, 51 ('torch.cuda.FloatTensor')
gt1, g2 = tensor 1,51,51
cfg.TRAIN.ASSO_W = 0.1

---
This is the search term to find the new lines of codes for PLCA in DACS: "TODO: required for PLCA"
how to find a experiment checkpoint path - follow inst in TODOV1.txt

extract the dacs baseline results from my and gurkirt euler and then take backup of those,
also the panoptic dacs backup 
and then remove them

the following are the different ways to integrate pixel level cycle association (plca) in dacs framework

approach 1: (running training)
    - take the source predction of the source by the model
    - take the target predction of the target by the ema_model
    - and apply plca loss as it is (that means you are not considering the GT of targets yet)
       
approach 3:
    - take the source predction of the source by the model
    - take the target predction of the target by the ema_model
    - and apply plca loss , but now you also consider the pseudo labels of target (by the ema_model)
     to filter out valid association
    
approach 5:
    - take the source predction of the source by the model
    - take the sythetic predction of the syntheitc augmentd image by the model
    - and apply plca loss , but now you also consider the pseudo labels of target (by the ema_model)
     to filter out valid association


The following is the code snippet to generate pseudo labels on the target:
    pred_target = ema_model(images_target)
    pred_target = get_module(ema_model, cfg.DISTRIBUTED).upsample_predictions(pred_target, input_shape_target)
    logits_u_w = pred_target['semantic']
    pseudo_label = torch.softmax(logits_u_w.detach(), dim=1)
    max_probs, targets_u_w = torch.max(pseudo_label, dim=1)
    
    The following code filter out the pseduo label
    the first line first 
    unlabeled_weight = torch.sum(max_probs.ge(0.968).long() == 1).item() / np.size(np.array(targets_u.cpu()))
    pixelWiseWeight = unlabeled_weight * torch.ones(max_probs.shape).to(DEVICE)
    
'''

cfg = {}
cfg['TRAIN'] = {}
cfg['TRAIN']['APPLY_SPAGG'] = True
cfg['TRAIN']['SPAGG_ALPHA'] = 0.5
cfg['TRAIN']['ASSO_TOPK'] = 1
cfg['TRAIN']['ASSO_PRINT_INFO'] = False
cfg['TRAIN']['ASSO_W'] = 0.1
cfg['DATASET'] = {}
cfg['DATASET']['IGNORE_LABEL'] = 255

ClsAssociationLoss = \
    AssociationLoss(
        metric='kl',
        spagg=True,
        spagg_alpha=0.5,
        asso_topk=1,
        print_info=False)

total_loss = 0
probs_S = torch.rand((1,16,51,51)).cuda().float()
probs_T = torch.rand((1,16,51,51)).cuda().float()
new_gt_S = torch.rand((1,51,51)).cuda().float()
new_gt_T = torch.rand((1,51,51)).cuda().float()
for i in range(10):
    start_time = perf_counter()
    ass_loss_classifier_dict = ClsAssociationLoss(probs_S, probs_T, new_gt_S, new_gt_T)
    torch.cuda.synchronize('cuda')
    ClsAssociationLoss_time = perf_counter() - start_time
    print('ClsAssociationLoss_time = {:.3f}'.format(ClsAssociationLoss_time))
# ass_loss_classifier = ass_loss_classifier_dict['association']
# total_loss += 0.1 * ass_loss_classifier
# print(total_loss)
# loss_meter_dict['ass_loss_classifier']

'''
/home/suman/apps/code/CVPR2022/pxl_cyc_uda/solver/loss.py

def associate_gt(self, gt, indices):
    gt is the train calss id 0,.., 15  - in this place
    indices are the association indices of HxW pixels based on either cos sim or kkl divergenr - this computed with out any GT information, purely based on distance metric learning (cos or kl)

    associated_gt = torch.gather(end_gt, 1, indices) : this line picks the gt labels (for each pixel) based on the source GT label and the assoication indices given by the distance metric (cosine sim or KL div)

    associated_gt is a tensor 1,2601,1 containing the class id (0,...,15)

    this assoication is purely based on the source GT and the assoication made by the KL div or cossine sim

    now we need to check if the associated GT are really matching the actual GT with the source

    because we don't have supervision on the target , so we do this:
    gt = (gt == associated_gt).type(torch.cuda.FloatTensor).detach()

    but, in our case, we have also superivison from the pseduolabel on the target, so we can make use of the that as well,
    so we can check if two pixels (from the source and target) which are associated using the KL div or cos sim metric
    are really belong to the same class by checking the associated_gt with source_gt and target_gt

    so the above line will be modifed as
    gt = ((source_gt == associated_gt) and (target_gt == associated_gt) ).type(torch.cuda.FloatTensor).detach()

    in this function we need only change this line
'''